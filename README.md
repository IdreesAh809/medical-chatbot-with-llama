# ğŸ©º MEDICAL-LLAMA-CHATBOT

This project is a **medical chatbot** built with **Ollama + Streamlit + FAISS**, designed to provide questionâ€“answering based on the open-source book *â€œWhere There Is No Doctorâ€*.  

ğŸ”¹ At first, the chatbot used **LLaMA-3:8B**, but since it was too large and slow on CPU, we switched to a **quantized model (`nous-hermes:7b-llama2-q4_K_M`)** for faster inference while still keeping good quality.  
ğŸ”¹ Everything runs **locally** â€” no paid GPU or API required.  

---

## ğŸ–¼ï¸ Demo UI

<p align="center" style="margin: 40px 0;">
  <img src="assets/MedicalBot-UI.png" alt="MedicalBot UI">
</p>



## ğŸ“‚ Project Structure

The file structure of the **MEDICAL-LLAMA-CHATBOT** project is as follows:

# medical-chatbot-with-llama
```medical-llama-chatbot/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yml
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploration.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader/
â”‚   â”‚   â””â”€â”€ pdf_loader.py
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â””â”€â”€ vector_store.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ llama_wrapper.py
â”‚   â”œâ”€â”€ qa/
â”‚   â”‚   â”œâ”€â”€ pipeline.py
â”‚   â”‚   â””â”€â”€ retriever.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ logger.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Features

- ğŸ” **Retrieval-Augmented Generation (RAG)** pipeline with FAISS embeddings  
- ğŸ“– Knowledge grounded in *Where There Is No Doctor*  
- âš¡ Optimized for **CPU-only machines** using quantized LLaMA-2 model  
- ğŸ’¬ **Streamlit chat UI** with conversation memory  
- ğŸ“ Easy to extend with new documents  


---

##  Installation & Setup

```
# 1. Clone the repository
git clone https://github.com/IdreesAh809/medical-chatbot-with-llama.git
cd medical-chatbot-with-llama

# 2. Create environment & Install dependencies
pip install -r requirements.txt

# 3. Install Ollama and pull the quantized model
ollama pull nous-hermes:7b-llama2-q4_K_M

# 4. Run the Streamlit app
streamlit run src/main.py
```
