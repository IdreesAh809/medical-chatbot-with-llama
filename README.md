# ğŸ©º MEDICAL-LLAMA-CHATBOT

This project is a **medical chatbot** built with **Ollama + Streamlit + FAISS**, designed to provide questionâ€“answering based on the open-source book *â€œWhere There Is No Doctorâ€*.  

ğŸ”¹ At first, the chatbot used **LLaMA-3:8B**, but since it was too large and slow on CPU, we switched to a **quantized model (`nous-hermes:7b-llama2-q4_K_M`)** for faster inference while still keeping good quality.  
ğŸ”¹ Everything runs **locally** â€” no paid GPU or API required.  

---

## ğŸ“‚ Project Structure

The file structure of the **MEDICAL-LLAMA-CHATBOT** project is as follows:

# medical-chatbot-with-llama
```medical-llama-chatbot/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yml
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploration.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader/
â”‚   â”‚   â””â”€â”€ pdf_loader.py
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â””â”€â”€ vector_store.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ llama_wrapper.py
â”‚   â”œâ”€â”€ qa/
â”‚   â”‚   â”œâ”€â”€ pipeline.py
â”‚   â”‚   â””â”€â”€ retriever.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ logger.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
